# Chapter 2 - Markov Decision Process

## Exercise 3.1  
Devise three example tasks of your own that fit into the MDP framework, identifying for
each its states, actions, and rewards. Make the three examples as different from each other as possible.
The framework is abstract and 
exible and can be applied in many different ways. Stretch its limits in
some way in at least one of your examples.

Solution 2.1   
|  Scenario|   Action      | State | Reward  |
|:--------:|:-------------:|:-----:|---|
| col 1 is |  left-aligned | $1600 |   |
| col 2 is |    centered   |  $12  |   |
| col 3 is | right-aligned |   $1  |   |
